services:
  dagster:
    build:
      context: .
      dockerfile: src/docker/Dockerfile.dagster
    ports:
      - "3000:3000"
      - "4000:4000"  # gRPC server port
    volumes:
      - .:/app
      - dagster_data:/data
      - dagster_home:/data/dagster_home
      - dagster_tmp:/tmp/dagster
      - model_storage:/data/models
      - ./src/docker/init-dagster.sh:/init-dagster.sh
    environment:
      - DAGSTER_HOME=/data/dagster_home
      - PYTHONPATH=/app
      - DAGSTER_GRPC_HOST=0.0.0.0
      - DAGSTER_GRPC_PORT=4000
      - OLLAMA_HOST=${OLLAMA_HOST:-http://localhost}
      - OLLAMA_PORT=${OLLAMA_PORT:-11434}
      - MODELS_DIR=/data/models
    healthcheck:
      test: 
        - CMD-SHELL
        - 'test -f /data/dagster_home/dagster.yaml && curl -f http://localhost:3000 || exit 1'
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        rm -f /data/dagster_home/dagster.yaml
        chmod +x /init-dagster.sh
        exec /init-dagster.sh
    restart: unless-stopped
    networks:
      - app_network

  streamlit:
    build:
      context: .
      dockerfile: src/docker/Dockerfile.streamlit
    ports:
      - "8501:8501"
    volumes:
      - .:/app
      - dagster_data:/data
      - dagster_home:/data/dagster_home
      - dagster_tmp:/tmp/dagster
      - model_storage:/data/models
    environment:
      - DAGSTER_HOME=/data/dagster_home
      - DAGSTER_HOST=dagster
      - DAGSTER_PORT=3000
      - PYTHONPATH=/app
      - DAGSTER_GRPC_HOST=dagster
      - DAGSTER_GRPC_PORT=4000
      - OLLAMA_HOST=${OLLAMA_HOST:-http://localhost}
      - OLLAMA_PORT=${OLLAMA_PORT:-11434}
      - MODELS_DIR=/data/models
    depends_on:
      dagster:
        condition: service_started
      ollama:
        condition: service_started
        required: false
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    restart: unless-stopped
    networks:
      - app_network

  ollama:
    profiles:
      - with-ollama
    image: ollama/ollama:latest
    platform: linux/arm64
    ports:
      - "11434:11434"
    volumes:
      - ollama_models:/root/.ollama
      - ./src/docker/init-ollama.sh:/init-ollama.sh
    deploy:
      resources:
        limits:
          memory: 16G
        reservations:
          memory: 4G
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_ORIGINS=*
      - OLLAMA_MODELS=/root/.ollama/models
      - OLLAMA_USE_MLX=true
      - OLLAMA_DOWNLOAD_TIMEOUT=300
      - OLLAMA_DOWNLOAD_RETRIES=3
    healthcheck:
      test: 
        - CMD-SHELL
        - 'curl -s -f "http://localhost:11434/api/tags" || exit 1'
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    ulimits:
      nofile:
        soft: 65535
        hard: 65535
    sysctls:
      - net.core.somaxconn=65535
    restart: unless-stopped
    networks:
      - app_network
    stop_grace_period: 60s

  eval:
    profiles:
      - eval
    build:
      context: .
      dockerfile: src/docker/Dockerfile.eval
    volumes:
      - .:/app
      - eval_data:/app/data
      - eval_cache:/app/data/eval_cache
      - ./data/eval_datasets:/app/data/eval_datasets:ro  # Mount datasets as read-only
    environment:
      - PYTHONPATH=/app
      - DAGSTER_HOME=/app/data
      - DAGSTER_GRPC_HOST=dagster
      - DAGSTER_GRPC_PORT=4000
      - OLLAMA_HOST=${OLLAMA_HOST:-http://localhost}
      - OLLAMA_PORT=${OLLAMA_PORT:-11434}
    depends_on:
      dagster:
        condition: service_healthy
    networks:
      - app_network

  test:
    build:
      context: .
      dockerfile: src/docker/Dockerfile.test
    volumes:
      - .:/app
    environment:
      - PYTHONPATH=/app
      - OLLAMA_HOST=http://localhost
      - OLLAMA_PORT=11434
    depends_on:
      ollama:
        condition: service_healthy
    profiles:
      - test
    networks:
      - app_network

networks:
  app_network:
    driver: bridge

volumes:
  dagster_data:
  dagster_home:
  dagster_tmp:
  model_storage:
  ollama_models:
  eval_data:
  eval_cache: 