services:
  dagster:
    build:
      context: .
      dockerfile: src/docker/Dockerfile.dagster
    ports:
      - "3000:3000"
      - "4000:4000"  # gRPC server port
    volumes:
      - .:/app
      - dagster_data:/data
      - dagster_home:/data/dagster_home
      - dagster_tmp:/tmp/dagster
      - model_storage:/data/models
    environment:
      - DAGSTER_HOME=/data/dagster_home
      - PYTHONPATH=/app
      - DAGSTER_GRPC_HOST=0.0.0.0
      - DAGSTER_GRPC_PORT=4000
      - OLLAMA_HOST=http://ollama
      - OLLAMA_PORT=11434
      - MODELS_DIR=/data/models
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    restart: unless-stopped
    networks:
      - app_network

  streamlit:
    build:
      context: .
      dockerfile: src/docker/Dockerfile.streamlit
    ports:
      - "8501:8501"
    volumes:
      - .:/app
      - dagster_data:/data
      - dagster_home:/data/dagster_home
      - dagster_tmp:/tmp/dagster
      - model_storage:/data/models
    environment:
      - DAGSTER_HOME=/data/dagster_home
      - DAGSTER_HOST=dagster
      - DAGSTER_PORT=3000
      - PYTHONPATH=/app
      - DAGSTER_GRPC_HOST=dagster
      - DAGSTER_GRPC_PORT=4000
      - OLLAMA_HOST=http://ollama
      - OLLAMA_PORT=11434
      - MODELS_DIR=/data/models
    depends_on:
      dagster:
        condition: service_started
      ollama:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    restart: unless-stopped
    networks:
      - app_network

  ollama:
    image: ollama/ollama:latest
    platform: linux/arm64
    ports:
      - "11434:11434"
    volumes:
      - ollama_models:/root/.ollama
    deploy:
      resources:
        limits:
          memory: 16G
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_ORIGINS=*
      - OLLAMA_MODELS=/root/.ollama/models
      - OLLAMA_USE_MLX=true
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags", "||", "exit", "0"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 60s
    restart: unless-stopped
    networks:
      - app_network

  test:
    build:
      context: .
      dockerfile: src/docker/Dockerfile.test
    volumes:
      - .:/app
    environment:
      - PYTHONPATH=/app
      - OLLAMA_HOST=http://ollama
      - OLLAMA_PORT=11434
    depends_on:
      ollama:
        condition: service_healthy
    profiles:
      - test
    networks:
      - app_network

networks:
  app_network:
    driver: bridge

volumes:
  dagster_data:
  dagster_home:
  dagster_tmp:
  model_storage:
  ollama_models: 