# LLM Configuration
LLM_PROVIDER=local-llama-cpp
LLM_MODEL_FILE=mistral-7b.gguf
LLM_MAX_TOKENS=2000
LLM_CONTEXT_LENGTH=8192
LLM_TEMPERATURE=0.1

# Processing Configuration
CHUNK_SIZE=1000
N_CLUSTERS=50
BATCH_SIZE=100
INIT_SIZE=10000
DB_PATH=/data/logs.duckdb

# Model Configuration
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Optional OpenAI Configuration
# OPENAI_API_KEY=your_key_here
# LLM_PROVIDER=openai
# LLM_MODEL_NAME=gpt-4 